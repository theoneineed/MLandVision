{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nabin Chapagain\n",
    "#1001551151\n",
    "\n",
    "\n",
    "#decision_tree(<training_file>, <test_file>, <option>, <pruning_thr>)\n",
    "\n",
    "# Importing all needed libraries\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "\n",
    "fname = 'yeast_training.txt'\n",
    "fname1 = 'yeast_test.txt'\n",
    "\n",
    "mat_train = np.loadtxt(fname)\n",
    "mat_test= np.loadtxt(fname1)\n",
    "\n",
    "train_max = mat_train[:,0:-1].max()\n",
    "\n",
    "no_train_mat_row = len(mat_train) \n",
    "no_train_mat_col = len(mat_train[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTL_Toplevel(examples, pruning_thr):#returns a decision tree\n",
    "    attributes = np.arange(0,no_train_mat_col-1,1,int)\n",
    "    default = DISTRIBUTION(examples)\n",
    "    return DTL(examples, attributes,default,pruning_thr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "\n",
    "    def __init__(self, best_attribute,best_threshold):\n",
    "\n",
    "        self.left_child = None\n",
    "        self.right_child = None\n",
    "        self.best_attribute = best_attribute\n",
    "        self.best_threshold = best_threshold\n",
    "\n",
    "\n",
    "    def PrintTree(self):\n",
    "        print(self.best_attribute)\n",
    "        print(self.best_threshold)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DISTRIBUTION(examples):\n",
    "    diff_classes = np.unique(examples[:,-1])\n",
    "    len_row = len(examples)\n",
    "    p_dist = np.zeros(len(diff_classes))\n",
    "    for i in range(len(diff_classes)):\n",
    "        cl_elem_ind = np.where(examples[:,-1] == diff_classes[i])\n",
    "        len_cl_ele = len(cl_elem_ind[0])\n",
    "        p_dist[i] = len_cl_ele/len_row\n",
    "    return p_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTL(examples, attributes, default, pruning_thr):\n",
    "    #returns a decision tree\n",
    "    size_of_classes = int((np.unique(examples[:,-1])).size)\n",
    "    if (len(examples)<pruning_thr):\n",
    "        return default\n",
    "    elif (size_of_classes == 1):\n",
    "        return examples[:][-1]\n",
    "    else:\n",
    "        examples_left =[]\n",
    "        examples_right =[]\n",
    "        (best_attribute, best_threshold)= CHOOSE_ATTRIBUTE_O(examples, attributes)\n",
    "        tree = Node(best_attribute, best_threshold)\n",
    "        for i in range(len(examples)):\n",
    "            if (examples[i][best_attribute]<best_threshold):\n",
    "                examples_left.append(examples[i])\n",
    "            else:\n",
    "                examples_right.append(examples[i])\n",
    "        examples_left = np.array(examples_left)\n",
    "        examples_right = np.array(examples_right)\n",
    "        dist = DISTRIBUTION(examples)\n",
    "        tree.left_child = DTL(examples_left, attributes, dist, pruning_thr)\n",
    "        tree.right_child = DTL(examples_right, attributes, dist, pruning_thr)\n",
    "        return tree\n",
    "#DTL(mat_train,np.arange(no_train_mat_col-1),1,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CHOOSE_ATTRIBUTE_O(examples, attributes):\n",
    "    #returns (attribute,threshold)\n",
    "    max_gain = best_attribute = best_threshold = -1\n",
    "    \n",
    "    for A in attributes:\n",
    "        attribute_values = examples[:,A]\n",
    "        L = np.amin(attribute_values)\n",
    "        M = np.amax(attribute_values)\n",
    "        for K in range(1,51):\n",
    "            threshold = L + (K*(M-L))/51\n",
    "            #gain = 25\n",
    "            gain = INFORMATION_GAIN(examples, A, threshold)\n",
    "            if (gain > max_gain):\n",
    "                max_gain = gain\n",
    "                best_attribute = A\n",
    "                best_threshold = threshold\n",
    "                #print(\"BA ..\")\n",
    "    return (best_attribute, best_threshold)\n",
    "#CHOOSE_ATTRIBUTE_O(mat_train,np.arange(0,no_train_mat_col-1,1,int))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RANDOM_ELEMENT(attributes):\n",
    "    return random.choice(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CHOOSE_ATTRIBUTE_R(examples, attributes):\n",
    "    #returns (attribute,threshold)\n",
    "    max_gain = best_threshold = -1\n",
    "    A = RANDOM_ELEMENT(attributes)\n",
    "    attribute_values = examples[:,A]\n",
    "    L = np.amin(attribute_values)\n",
    "    M = np.amax(attribute_values)\n",
    "    for K in range(1,51):\n",
    "        threshold = L+K*(M - L)/51\n",
    "        gain = INFORMATION_GAIN(examples, A, threshold)\n",
    "        if (gain > max_gain):\n",
    "            max_gain = gain\n",
    "            best_threshold = threshold\n",
    "    return (A, best_threshold)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Entropy_calc(dist):\n",
    "    entr = 0\n",
    "    for i in range(0,len(dist)):\n",
    "        entr = entr - dist[i]*np.log2(dist[i])\n",
    "    return entr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def INFORMATION_GAIN(examples, A, threshold):\n",
    "    examples_left =[]\n",
    "    examples_right =[]\n",
    "    \n",
    "    for i in range(len(examples)):\n",
    "        if (examples[i][A] < threshold):\n",
    "            examples_left.append(examples[i])\n",
    "        else:\n",
    "            examples_right.append(examples[i])\n",
    "    examples_left = np.array(examples_left)\n",
    "    examples_right = np.array(examples_right)\n",
    "    \n",
    "    dist = DISTRIBUTION(examples)\n",
    "    dist_left = DISTRIBUTION(examples_left)\n",
    "    dist_right = DISTRIBUTION(examples_right)\n",
    "    inf_gain = Entropy_calc(dist)- Entropy_calc(dist_left)-Entropy_calc(dist_right)\n",
    "    return inf_gain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_level = DTL_Toplevel(mat_train, 50)\n",
    "#print('tree=%2d, node=%3d, feature=%2d, thr=%6.2f, gain=%f\\n', tree_id, node_id, feature_id, threshold, gain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was getting hard to use notebook to solve this question so I moved to Vscode.\n"
     ]
    }
   ],
   "source": [
    "print(\"It was getting hard to use notebook to solve this question so I moved to Vscode.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
